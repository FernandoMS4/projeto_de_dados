![Python](https://img.shields.io/badge/Python-3.11.5-blue?logo=python&logoColor=white)
![Airflow](https://img.shields.io/badge/Airflow-2.8+-brightgreen?logo=apache-airflow)
![Poetry](https://img.shields.io/badge/Poetry-managed-8c8c8c?logo=python)

ğŸ“Š Projeto de Eng de Dados Ponta

Opa bÃ£o? ğŸ˜‰

Este projeto tem como objetivo implementar uma pipeline de ETL utilizando Apache Airflow orquestrado via Astronomer, com containers Docker e controle de ambiente virtual via Poetry.

Este projeto foi feito no ambiente linux

ğŸ”§ Tecnologias Utilizadas

    - Python 3.11.5
    - Apache Airflow
    - Astronomer CLI
    - Docker
    - Poetry
    - Pytest

âš™ï¸ ExecuÃ§Ã£o e OrquestraÃ§Ã£o

Todo o pipeline foi orquestrado com:

    Apache Airflow, utilizando o Astronomer CLI para facilitar a execuÃ§Ã£o local com Docker.

    Docker para conteinerizaÃ§Ã£o do ambiente completo (Airflow + dependÃªncias).

    Poetry para gestÃ£o de dependÃªncias e ambiente virtual.

    Pytest para execuÃ§Ã£o de testes unitÃ¡rios garantindo a qualidade das funÃ§Ãµes crÃ­ticas.

ğŸ“¦ Como rodar o projeto localmente

    1. Clone o repositÃ³rio

        - git clone https://github.com/FernandoMS4/projeto_de_dados.git

        - cd projeto_de_dados

        - code .

ğŸš€ Rodando com Astronomer + Docker
    
    1. Instale o Astronomer CLI
        
        > No linux: curl -sSL install.astronomer.io | sudo bash -s  
    
        > Verifique a versÃ£o do astronomer: astro version
    
        > Caso esteja no Windows utilize o WSL para configurar o ambiente ou installe pelo comandod choco install astronomer
        
        OBS: Requer Chocolatey

    2. Inicie o ambiente local com Docker

        - astro dev start

    3. Caso queia visualizar ou baixar o arquivo parquet:
        1. Para identificar seus containers
        - docker ps

        2. Para entrar no ambiente 
        - docker exec -it processo-dados2_5c5e37-scheduler-1 /bin/bash

        3. Para identificar o arquivo gerado
        - cd archive && ls

        VocÃª vai identificar o arquivo no seguinte formato
        - boi_gordo_YYYY-MM-DD.parquet

        4. Para copiar o arquivo para o ambiente local
        - docker cp <ID do container>:/usr/local/airflow/archive/boi_gordo.parquet .


ğŸ“ Estrutura de arquivos

    â”œâ”€â”€ airflow_settings.yaml
    â”œâ”€â”€ archive
    â”‚   â”œâ”€â”€ boi_gordo_base.csv
    â”‚   â”œâ”€â”€ boi_gordo.parquet
    â”‚   â””â”€â”€ CEPEA-20250416134013.xlsx
    â”œâ”€â”€ dags
    â”‚   â”œâ”€â”€ etl_boigordo.py
    â”‚   â”œâ”€â”€ exampledag.py
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ __pycache__
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ include
    â”‚   â”œâ”€â”€ extract.py
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ load.py
    â”‚   â”œâ”€â”€ main.py
    â”‚   â”œâ”€â”€ __pycache__
    â”‚   â””â”€â”€ transform.py
    â”œâ”€â”€ packages.txt
    â”œâ”€â”€ plugins
    â”œâ”€â”€ poetry.lock
    â”œâ”€â”€ pyproject.toml
    â”œâ”€â”€ README.md
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ tests
        â”œâ”€â”€ dags
        â””â”€â”€ etl


Um pouco do processo rodando:

        ![alt text](/archive/images/image.png)